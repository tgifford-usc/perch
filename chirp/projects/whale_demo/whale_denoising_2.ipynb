{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92cc35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Only run this code if you need to install perch-hoplite\n",
    "#@markdown You will likely be asked to restart your runtime, but after restarting, don't need to rerun this block.\n",
    "!pip install git+https://github.com/google-research/perch-hoplite.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc79960f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Imports\n",
    "from etils import epath\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "from perch_hoplite.agile import colab_utils\n",
    "from perch_hoplite.agile import embed\n",
    "from perch_hoplite.agile import source_info\n",
    "from perch_hoplite.db import brutalism\n",
    "from perch_hoplite.db import interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1aa16ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Mount Google Drive for saving data\n",
    "#@markdown When you run this, you will be prompted to authenticate to grant permissions for colab to save to your Google Drive.\n",
    "\n",
    "#@markdown After you grant permissions, you will see a code that you will need to copy and paste in the form output that will be generated below.\n",
    "import os\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b42237",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Create a new folder in Drive (if it doesn't already exist) within your Google drive.\n",
    "base_dir = '/content/drive/My Drive/'\n",
    "#@ markdown Name of your new folder in Drive\n",
    "new_folder_name = 'noaa_demo' #@param\n",
    "\n",
    "drive_output_directory = base_dir + new_folder_name\n",
    "\n",
    "try:\n",
    "  if not os.path.exists(drive_output_directory):\n",
    "    os.makedirs(drive_output_directory, exist_ok=True)\n",
    "    print(f'Directory {drive_output_directory} created successfully.')\n",
    "  else:\n",
    "    print(f'Directory {drive_output_directory} already exists.')\n",
    "except OSError as e:\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14774a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "@title Configuration { vertical-output: true }\n",
    "\n",
    "# @markdown Configure the raw dataset and output location(s).  The format is a mapping from\n",
    "# @markdown a dataset_name to a (base_path, fileglob) pair.  Note that the file\n",
    "# @markdown globs are case sensitive.  The dataset name can be anything you want.\n",
    "#\n",
    "# @markdown This structure allows you to move your data around without having to\n",
    "# @markdown re-embed the dataset.  The generated embedding database will be\n",
    "# @markdown placed in the base path. This allows you to simply swap out\n",
    "# @markdown the base path here if you ever move your dataset.\n",
    "\n",
    "# @markdown By default we only process one dataset at a time.  Re-run this entire portion [Embed] of the notebook\n",
    "# @markdown once per dataset.\n",
    "\n",
    "# @markdown For example, we might set dataset_base_path to '/home/me/myproject',\n",
    "# @markdown and use the glob '\\*/\\*.wav' if all of the audio files have filepaths\n",
    "# @markdown like '/home/me/myproject/site_XYZ/audio_ABC.wav' (e.g. audio files are contained in subfolders of the base directory).\n",
    "\n",
    "\n",
    "# @markdown 1. Create a unique name for the database that will store the embeddings for the target data.\n",
    "# @markdown For this example, we use the name of the large audio file, but you can use a different name here.\n",
    "dataset_name = 'Saipan_A_06_151006_091215'  # @param {type:'string'}\n",
    "# @markdown 2. Input the filepath for the folder that is containing the input audio files.\n",
    "dataset_base_path = 'gs://noaa-passive-bioacoustic/pifsc/audio/pipan/saipan/pipan_saipan_06/audio'  #@param {type:'string'}\n",
    "# @markdown 3. Input the file pattern for the audio files within that folder that you want to embed. Some examples for how to input:\n",
    "# @markdown - All files in the base directory of a specific type (not subdirectories): e.g. `*.wav` (or `*.flac` etc) will generate embeddings for all .wav files (or whichever format) in the dataset_base_path\n",
    "# @markdown - All files in one level of subdirectories within the base directory: `*/*.flac` will generate embeddings for all .flac files\n",
    "# @markdown - Single file: `myfile.wav` will only embed the audio from that specific file.\n",
    "dataset_fileglob = 'Saipan_A_06_151006_091215.df20.*.flac'  # @param {type:'string'}\n",
    "\n",
    "# @markdown 4. [Optional] If saving the embeddings database to a new directory, specify here.\n",
    "# @markdown Otherwise, leave blank - by default the embeddings database output will be saved within\n",
    "# @markdown dataset_base_path where the audio is located. You do not need to specify db_path unless you want to maintain multiple\n",
    "# @markdown distinct embedding databases, or if you would like to save the output\n",
    "# @markdown in a different folder. If your input audio data is accessed\n",
    "# @markdown from a public URL, we recommend specifying a separate output directory here.\n",
    "db_subdir = '/agile_Saipan_A_06_151006_091215'  # @param {type:'string'}\n",
    "db_path = drive_output_directory + db_subdir if db_subdir else None\n",
    "if not db_path or db_path == 'None':\n",
    "  db_path = None\n",
    "\n",
    "\n",
    "# @markdown 5. Choose a supported model to generate embeddings: `perch_8` or `birdnet_v2.3` are most common\n",
    "# @markdown for birds. Other choices include `surfperch` for coral reefs or\n",
    "# @markdown `multispecies_whale` for marine mammals.\n",
    "model_choice = 'surfperch'  #@param['perch_8', 'humpback', 'multispecies_whale', 'surfperch', 'birdnet_V2.3']\n",
    "\n",
    "# @markdown 6. [Optional] Shard the audio for embeddings. File sharding automatically splits audio files into smaller chunks\n",
    "# @markdown for creating embeddings. This limits both system and GPU memory usage,\n",
    "# @markdown especially useful when working with long files (>1 hour).\n",
    "use_file_sharding = True  # @param {type:'boolean'}\n",
    "# @markdown If you want to change the length in seconds for the shards, specify here.\n",
    "shard_length_in_seconds = 75  # @param {type:'number'}\n",
    "\n",
    "# @markdown We also need to specify the targeted sample rate. -2 will give the target sample rate of the model,\n",
    "# @markdown -1 will use the target sample rate of the original source audio, and any other number >0 will\n",
    "# @markdown use that specified rate.\n",
    "target_sample_rate_hz = -1  # @param {type:'number'}\n",
    "\n",
    "audio_glob = source_info.AudioSourceConfig(\n",
    "    dataset_name=dataset_name,\n",
    "    base_path=dataset_base_path,\n",
    "    file_glob=dataset_fileglob,\n",
    "    min_audio_len_s=1.0,\n",
    "    target_sample_rate_hz=target_sample_rate_hz,\n",
    "    shard_len_s=float(shard_length_in_seconds) if use_file_sharding else None,\n",
    ")\n",
    "\n",
    "configs = colab_utils.load_configs(\n",
    "    source_info.AudioSources((audio_glob,)),\n",
    "    db_path,\n",
    "    model_config_key=model_choice,\n",
    "    db_key='sqlite_usearch',\n",
    ")\n",
    "configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38ecf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Initialize the hoplite database (DB) { vertical-output: true }\n",
    "global db\n",
    "db = configs.db_config.load_db()\n",
    "num_embeddings = db.count_embeddings()\n",
    "\n",
    "print('Initialized DB located at ', configs.db_config.db_config.db_path)\n",
    "\n",
    "def drop_and_reload_db(_) -> interface.HopliteDBInterface:\n",
    "  db_path = epath.Path(configs.db_config.db_config.db_path)\n",
    "  for fp in db_path.glob('hoplite.sqlite*'):\n",
    "    fp.unlink()\n",
    "  (db_path / 'usearch.index').unlink()\n",
    "  print('\\n Deleted previous db at: ', configs.db_config.db_config.db_path)\n",
    "  db = configs.db_config.load_db()\n",
    "\n",
    "#@markdown If `drop_existing_db` set to True, when the database already exists and contains embeddings,\n",
    "#@markdown then those existing embeddings will be erased. You will be prompted to confirm you wish to delete those existing\n",
    "#@markdown embeddings. If you want to keep existing embeddings in the database, then set to False, which will append the new\n",
    "#@markdown embeddings to the database.\n",
    "drop_existing_db = False  #@param {type:'boolean'}\n",
    "\n",
    "if num_embeddings > 0 and drop_existing_db:\n",
    "  print('Existing DB contains datasets: ', db.get_dataset_names())\n",
    "  print('num embeddings: ', num_embeddings)\n",
    "  print('\\n\\nClick the button below to confirm you really want to drop the database at ')\n",
    "  print(f'{configs.db_config.db_config.db_path}\\n')\n",
    "  print(f'This will permanently delete all {num_embeddings} embeddings from the existing database.\\n')\n",
    "  print('If you do NOT want to delete this data, set `drop_existing_db` above to `False` and re-run this cell.\\n')\n",
    "\n",
    "  button = widgets.Button(description='Delete database?')\n",
    "  button.on_click(drop_and_reload_db)\n",
    "  display(button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bfbf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Run the embedding { vertical-output: true }\n",
    "#@markdown This may take approximately 15 minutes to run.\n",
    "\n",
    "print(f'Embedding dataset: {audio_glob.dataset_name}')\n",
    "\n",
    "worker = embed.EmbedWorker(\n",
    "    audio_sources=configs.audio_sources_config,\n",
    "    db=db,\n",
    "    model_config=configs.model_config)\n",
    "\n",
    "worker.process_all(target_dataset_name=audio_glob.dataset_name)\n",
    "\n",
    "print('\\n\\nEmbedding complete, total embeddings: ', db.count_embeddings())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
