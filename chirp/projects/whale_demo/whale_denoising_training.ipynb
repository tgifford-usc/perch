{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üõ†Ô∏è Setup\n",
    "!pip install librosa torchaudio matplotlib einops -q\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üóíÔ∏è Config\n",
    "DATA_DIR = '/content/drive/MyDrive/whale_denoising'\n",
    "NOISY_DIR = f'{DATA_DIR}/noisy'\n",
    "CLEAN_DIR = f'{DATA_DIR}/clean'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÇ Clone your forked perch repo\n",
    "!git clone https://github.com/tgifford-usc/perch.git\n",
    "%cd perch\n",
    "!pip install -e .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üßê Load whale embedding model from the demo notebook itself\n",
    "import sys\n",
    "sys.path.append('/content/perch/chirp/projects/whale_demo')\n",
    "from agile_modeling_noaa_demo import get_model_config, load_and_build_model\n",
    "model_config = get_model_config()\n",
    "embedding_model = load_and_build_model(model_config, include_frontend=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéµ Load audio\n",
    "import glob\n",
    "import torch\n",
    "import torchaudio\n",
    "def load_audio(path):\n",
    "    wav, sr = torchaudio.load(path)\n",
    "    assert sr == 10000\n",
    "    return wav[0]\n",
    "def load_dataset(noisy_dir, clean_dir):\n",
    "    noisy_paths = sorted(glob.glob(noisy_dir + '/*.wav'))\n",
    "    clean_paths = sorted(glob.glob(clean_dir + '/*.wav'))\n",
    "    noisy = [load_audio(p) for p in noisy_paths]\n",
    "    clean = [load_audio(p) for p in clean_paths][:len(noisy)]\n",
    "    return noisy[:len(clean)], clean\n",
    "noisy_data, clean_data = load_dataset(NOISY_DIR, CLEAN_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÄ Dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class WhaleDenoiseDataset(Dataset):\n",
    "    def __init__(self, noisy, clean):\n",
    "        self.noisy = noisy\n",
    "        self.clean = clean\n",
    "    def __len__(self):\n",
    "        return len(self.noisy)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.noisy[idx], self.clean[idx]\n",
    "train_dataset = WhaleDenoiseDataset(noisy_data, clean_data)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üßπ Denoiser model\n",
    "import torch.nn as nn\n",
    "class Denoiser1D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, kernel_size=15, padding=7),\n",
    "            nn.ReLU(),\n    "            nn.Conv1d(32, 64, kernel_size=15, padding=7),\n    "            nn.ReLU(),\n    "            nn.Conv1d(64, 32, kernel_size=15, padding=7),\n    "            nn.ReLU(),\n    "            nn.Conv1d(32, 1, kernel_size=15, padding=7)\n    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "denoiser = Denoiser1D().cuda()\n",
    "optimizer = torch.optim.Adam(denoiser.parameters(), lr=1e-3)\n",
    "mse_loss = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚Ü∫ Training loop\n",
    "from tqdm import tqdm\n",
    "for epoch in range(10):\n",
    "    denoiser.train()\n",
    "    total_loss = 0\n",
    "    for noisy, clean in tqdm(train_loader):\n",
    "        noisy = noisy.unsqueeze(1).cuda()\n",
    "        clean = clean.unsqueeze(1).cuda()\n",
    "        output = denoiser(noisy)\n",
    "        loss = mse_loss(output, clean)\n",
    "        with torch.no_grad():\n",
    "            embed_clean = embedding_model.get_embeddings(clean.squeeze(1)).detach()\n",
    "            embed_denoised = embedding_model.get_embeddings(output.squeeze(1))\n",
    "        embed_loss = ((embed_clean - embed_denoised)**2).mean()\n",
    "        total = loss + 0.1 * embed_loss\n",
    "        optimizer.zero_grad()\n",
    "        total.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += total.item()\n",
    "    print(f'Epoch {epoch+1}, Loss = {total_loss/len(train_loader):.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
